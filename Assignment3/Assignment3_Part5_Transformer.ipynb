{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M2177.003100 Deep Learning <br> Assignment #3 Part 5: Transformer\n",
    "\n",
    "Copyright (C) Data Science Laboratory, Seoul National University. This material is for educational uses only. Some contents are based on the material provided by other paper/book authors and may be copyrighted by them. Written by Jeonghee Jo, October 2019\n",
    "\n",
    "This is about Transformer (Vaswani et al., 2017).\n",
    "https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf\n",
    "\n",
    "Original blog post & code:\n",
    "https://github.com/Kyubyong/transformer\n",
    "##### Copyright 2019 The TensorFlow Authors.\n",
    "\n",
    "That said, you are allowed to copy paste the codes from the original repo.\n",
    "HOWEVER, <font color=red> try to implement the model yourself first </font>, and consider the original source code as a last resort.\n",
    "You will learn a lot while wrapping around your head during the implementation. And you will understand nuts and bolts of RNNs more clearly in a code level.\n",
    "\n",
    "### Submitting your work:\n",
    "<font color=red>**DO NOT clear the final outputs**</font> so that TAs can grade both your code and results.  \n",
    "Once you have done **all Assignment Part 1-5**, run the *CollectSubmission.sh* script with your **Team number** as input argument. <br>\n",
    "This will produce a zipped file called *[Your team number].zip*. Please submit this file on ETL. &nbsp;&nbsp; (Usage: ./*CollectSubmission.sh* team_#)\n",
    "\n",
    "### Transformer (20 points)\n",
    "\n",
    "This assignment is an on/off one: just make this notebook **\"work\"** without problem by: \n",
    "\n",
    "1. **Explore various hyperparameters and pick the best set (in class Hparams, transformer_modules.py)** \n",
    "\n",
    "### The Grading is as follows:\n",
    "\n",
    "1. Train your model using at least <font color=red> 12 different hyperparameter set </font>. Report performance results (BLEU score) on given test set <font color=red> for corresponding each hyperparameter set </font>. \n",
    "\n",
    "2. Plus, <font color=red> submit the one checkpoint file </font> of your best model. \n",
    "\n",
    "The details are described in <font color=red>**transformer_modules.py**</font>. (There is nothing to implement in this notebook.)\n",
    "\n",
    "\n",
    "Now proceed to the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_utils import *\n",
    "from transformer_modules import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import argparse\n",
    "import math\n",
    "import os\n",
    "import errno\n",
    "import sentencepiece as spm\n",
    "import re\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro(hp):\n",
    "    \"\"\"Load raw data -> Preprocessing -> Segmenting with sentencepice\n",
    "    hp: hyperparams. argparse.\n",
    "    \"\"\"\n",
    "    \n",
    "    train1 = \"./iwslt2016/de-en/train.tags.de-en.de\"\n",
    "    train2 = \"./iwslt2016/de-en/train.tags.de-en.en\"\n",
    "    eval1 = \"./iwslt2016/de-en/IWSLT16.TED.tst2013.de-en.de.xml\"\n",
    "    eval2 = \"./iwslt2016/de-en/IWSLT16.TED.tst2013.de-en.en.xml\"\n",
    "    test1 = \"./iwslt2016/de-en/IWSLT16.TED.tst2014.de-en.de.xml\"\n",
    "    test2 = \"./iwslt2016/de-en/IWSLT16.TED.tst2014.de-en.en.xml\"\n",
    "    for f in (train1, train2, eval1, eval2, test1, test2):\n",
    "        if not os.path.isfile(f):\n",
    "            raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), f)\n",
    "\n",
    "    # train\n",
    "    _prepro = lambda x:  [line.strip() for line in open(x, 'r').read().split(\"\\n\") \\\n",
    "                      if not line.startswith(\"<\")]\n",
    "    prepro_train1, prepro_train2 = _prepro(train1), _prepro(train2)\n",
    "    assert len(prepro_train1)==len(prepro_train2), \"Check if train source and target files match.\"\n",
    "\n",
    "    # eval\n",
    "    _prepro = lambda x: [re.sub(\"<[^>]+>\", \"\", line).strip() \\\n",
    "                     for line in open(x, 'r').read().split(\"\\n\") \\\n",
    "                     if line.startswith(\"<seg id\")]\n",
    "    prepro_eval1, prepro_eval2 = _prepro(eval1), _prepro(eval2)\n",
    "    assert len(prepro_eval1) == len(prepro_eval2), \"Check if eval source and target files match.\"\n",
    "\n",
    "    # test\n",
    "    prepro_test1, prepro_test2 = _prepro(test1), _prepro(test2)\n",
    "    assert len(prepro_test1) == len(prepro_test2), \"Check if test source and target files match.\"\n",
    "\n",
    "    os.makedirs(\"./iwslt2016/prepro\", exist_ok=True)\n",
    "    def _write(sents, fname):\n",
    "        with open(fname, 'w') as fout:\n",
    "            fout.write(\"\\n\".join(sents))\n",
    "\n",
    "    _write(prepro_train1, \"./iwslt2016/prepro/train.de\")\n",
    "    _write(prepro_train2, \"./iwslt2016/prepro/train.en\")\n",
    "    _write(prepro_train1+prepro_train2, \"./iwslt2016/prepro/train\")\n",
    "    _write(prepro_eval1, \"./iwslt2016/prepro/eval.de\")\n",
    "    _write(prepro_eval2, \"./iwslt2016/prepro/eval.en\")\n",
    "    _write(prepro_test1, \"./iwslt2016/prepro/test.de\")\n",
    "    _write(prepro_test2, \"./iwslt2016/prepro/test.en\")\n",
    "\n",
    "    os.makedirs(\"./iwslt2016/segmented\", exist_ok=True)\n",
    "    train = '--input=./iwslt2016/prepro/train --pad_id=0 --unk_id=1 \\\n",
    "             --bos_id=2 --eos_id=3\\\n",
    "             --model_prefix=./iwslt2016/segmented/bpe --vocab_size={} \\\n",
    "             --model_type=bpe'.format(hp.vocab_size)\n",
    "    #print(train)\n",
    "    spm.SentencePieceTrainer.Train(train)\n",
    "\n",
    "    sp = spm.SentencePieceProcessor()\n",
    "    sp.Load(\"./iwslt2016/segmented/bpe.model\")\n",
    "\n",
    "    def _segment_and_write(sents, fname):\n",
    "        with open(fname, \"w\") as fout:\n",
    "            for sent in sents:\n",
    "                pieces = sp.EncodeAsPieces(sent)\n",
    "                fout.write(\" \".join(pieces) + \"\\n\")\n",
    "\n",
    "    _segment_and_write(prepro_train1, \"./iwslt2016/segmented/train.de.bpe\")\n",
    "    _segment_and_write(prepro_train2, \"./iwslt2016/segmented/train.en.bpe\")\n",
    "    _segment_and_write(prepro_eval1, \"./iwslt2016/segmented/eval.de.bpe\")\n",
    "    _segment_and_write(prepro_eval2, \"./iwslt2016/segmented/eval.en.bpe\")\n",
    "    _segment_and_write(prepro_test1, \"./iwslt2016/segmented/test.de.bpe\")\n",
    "\n",
    "    print(\"train1:\", open(\"./iwslt2016/segmented/train.de.bpe\",'r').readline())\n",
    "    print(\"train2:\", open(\"./iwslt2016/segmented/train.en.bpe\", 'r').readline())\n",
    "    print(\"eval1:\", open(\"./iwslt2016/segmented/eval.de.bpe\", 'r').readline())\n",
    "    print(\"eval2:\", open(\"./iwslt2016/segmented/eval.en.bpe\", 'r').readline())\n",
    "    print(\"test1:\", open(\"./iwslt2016/segmented/test.de.bpe\", 'r').readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train1: ▁D a v id ▁G all o : ▁Das ▁ist ▁B ill ▁L ange . ▁Ich ▁bin ▁D a ve ▁G all o .\n",
      "\n",
      "train2: ▁D a v id ▁G all o : ▁This ▁is ▁B ill ▁L ange . ▁I ' m ▁D a ve ▁G all o .\n",
      "\n",
      "eval1: ▁Als ▁ich ▁1 1 ▁J ahre ▁al t ▁war , ▁wurde ▁ich ▁eines ▁M or gen s ▁von ▁den ▁K l än gen ▁h ell er ▁F re u de ▁ge we ck t .\n",
      "\n",
      "eval2: ▁Wh en ▁I ▁was ▁1 1 , ▁I ▁re m em ber ▁w ak ing ▁up ▁one ▁m or n ing ▁to ▁the ▁s ound ▁of ▁j o y ▁in ▁my ▁h ou se .\n",
      "\n",
      "test1: ▁Als ▁ich ▁in ▁mein en ▁20 ern ▁war , ▁hatte ▁ich ▁meine ▁er ste ▁P s y ch other ap ie - P at ient in .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hparams = Hparams()\n",
    "parser = hparams.parser\n",
    "hp = parser.parse_args()\n",
    "hp.vocab_size=1000\n",
    "prepro(hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer:\n",
    "    '''\n",
    "    xs: tuple of\n",
    "        x: int32 tensor. (N, T1)\n",
    "        x_seqlens: int32 tensor. (N,)\n",
    "        sents1: str tensor. (N,)\n",
    "    ys: tuple of\n",
    "        decoder_input: int32 tensor. (N, T2)\n",
    "        y: int32 tensor. (N, T2)\n",
    "        y_seqlen: int32 tensor. (N, )\n",
    "        sents2: str tensor. (N,)\n",
    "    training: boolean.\n",
    "    '''\n",
    "    def __init__(self, hp):\n",
    "        self.hp = hp\n",
    "        self.token2idx, self.idx2token = load_vocab(hp.vocab)\n",
    "        self.embeddings = get_token_embeddings(self.hp.vocab_size, self.hp.d_model, zero_pad=True)\n",
    "\n",
    "    def encode(self, xs, training=True):\n",
    "        '''\n",
    "        Returns\n",
    "        memory: encoder outputs. (N, T1, d_model)\n",
    "        '''\n",
    "        with tf.variable_scope(\"encoder\", reuse=tf.AUTO_REUSE):\n",
    "            x, seqlens, sents1 = xs\n",
    "\n",
    "            # src_masks\n",
    "            src_masks = tf.math.equal(x, 0) # (N, T1)\n",
    "\n",
    "            # embedding\n",
    "            enc = tf.nn.embedding_lookup(self.embeddings, x) # (N, T1, d_model)\n",
    "            enc *= self.hp.d_model**0.5 # scale\n",
    "\n",
    "            enc += positional_encoding(enc, self.hp.maxlen1)\n",
    "            enc = tf.layers.dropout(enc, self.hp.dropout_rate, training=training)\n",
    "\n",
    "            ## Blocks\n",
    "            for i in range(self.hp.num_blocks):\n",
    "                with tf.variable_scope(\"num_blocks_{}\".format(i), reuse=tf.AUTO_REUSE):\n",
    "                    # self-attention\n",
    "                    enc = multihead_attention(queries=enc,\n",
    "                                              keys=enc,\n",
    "                                              values=enc,\n",
    "                                              key_masks=src_masks,\n",
    "                                              num_heads=self.hp.num_heads,\n",
    "                                              dropout_rate=self.hp.dropout_rate,\n",
    "                                              training=training,\n",
    "                                              causality=False)\n",
    "                    # feed forward\n",
    "                    enc = ff(enc, num_units=[self.hp.d_ff, self.hp.d_model])\n",
    "        memory = enc\n",
    "        return memory, sents1, src_masks\n",
    "\n",
    "    def decode(self, ys, memory, src_masks, training=True):\n",
    "        '''\n",
    "        memory: encoder outputs. (N, T1, d_model)\n",
    "        src_masks: (N, T1)\n",
    "        Returns\n",
    "        logits: (N, T2, V). float32.\n",
    "        y_hat: (N, T2). int32\n",
    "        y: (N, T2). int32\n",
    "        sents2: (N,). string.\n",
    "        '''\n",
    "        with tf.variable_scope(\"decoder\", reuse=tf.AUTO_REUSE):\n",
    "            decoder_inputs, y, seqlens, sents2 = ys\n",
    "\n",
    "            # tgt_masks\n",
    "            tgt_masks = tf.math.equal(decoder_inputs, 0)  # (N, T2)\n",
    "\n",
    "            # embedding\n",
    "            dec = tf.nn.embedding_lookup(self.embeddings, decoder_inputs)  # (N, T2, d_model)\n",
    "            dec *= self.hp.d_model ** 0.5  # scale\n",
    "\n",
    "            dec += positional_encoding(dec, self.hp.maxlen2)\n",
    "            dec = tf.layers.dropout(dec, self.hp.dropout_rate, training=training)\n",
    "\n",
    "            # Blocks\n",
    "            for i in range(self.hp.num_blocks):\n",
    "                with tf.variable_scope(\"num_blocks_{}\".format(i), reuse=tf.AUTO_REUSE):\n",
    "                    # Masked self-attention (Note that causality is True at this time)\n",
    "                    dec = multihead_attention(queries=dec,\n",
    "                                              keys=dec,\n",
    "                                              values=dec,\n",
    "                                              key_masks=tgt_masks,\n",
    "                                              num_heads=self.hp.num_heads,\n",
    "                                              dropout_rate=self.hp.dropout_rate,\n",
    "                                              training=training,\n",
    "                                              causality=True,\n",
    "                                              scope=\"self_attention\")\n",
    "\n",
    "                    # Vanilla attention\n",
    "                    dec = multihead_attention(queries=dec,\n",
    "                                              keys=memory,\n",
    "                                              values=memory,\n",
    "                                              key_masks=src_masks,\n",
    "                                              num_heads=self.hp.num_heads,\n",
    "                                              dropout_rate=self.hp.dropout_rate,\n",
    "                                              training=training,\n",
    "                                              causality=False,\n",
    "                                              scope=\"vanilla_attention\")\n",
    "                    ### Feed Forward\n",
    "                    dec = ff(dec, num_units=[self.hp.d_ff, self.hp.d_model])\n",
    "\n",
    "        # Final linear projection (embedding weights are shared)\n",
    "        weights = tf.transpose(self.embeddings) # (d_model, vocab_size)\n",
    "        logits = tf.einsum('ntd,dk->ntk', dec, weights) # (N, T2, vocab_size)\n",
    "        y_hat = tf.to_int32(tf.argmax(logits, axis=-1))\n",
    "\n",
    "        return logits, y_hat, y, sents2\n",
    "\n",
    "    def train(self, xs, ys):\n",
    "        '''\n",
    "        Returns\n",
    "        loss: scalar.\n",
    "        train_op: training operation\n",
    "        global_step: scalar.\n",
    "        summaries: training summary node\n",
    "        '''\n",
    "        # forward\n",
    "        memory, sents1, src_masks = self.encode(xs)\n",
    "        logits, preds, y, sents2 = self.decode(ys, memory, src_masks)\n",
    "\n",
    "        # train scheme\n",
    "        y_ = label_smoothing(tf.one_hot(y, depth=self.hp.vocab_size))\n",
    "        ce = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y_)\n",
    "        nonpadding = tf.to_float(tf.not_equal(y, self.token2idx[\"<pad>\"]))  # 0: <pad>\n",
    "        loss = tf.reduce_sum(ce * nonpadding) / (tf.reduce_sum(nonpadding) + 1e-7)\n",
    "\n",
    "        global_step = tf.train.get_or_create_global_step()\n",
    "        lr = noam_scheme(self.hp.lr, global_step, self.hp.warmup_steps)\n",
    "        optimizer = tf.train.AdamOptimizer(lr)\n",
    "        train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "        tf.summary.scalar('lr', lr)\n",
    "        tf.summary.scalar(\"loss\", loss)\n",
    "        tf.summary.scalar(\"global_step\", global_step)\n",
    "\n",
    "        summaries = tf.summary.merge_all()\n",
    "\n",
    "        return loss, train_op, global_step, summaries\n",
    "\n",
    "    def eval(self, xs, ys):\n",
    "        '''Predicts autoregressively\n",
    "        At inference, input ys is ignored.\n",
    "        Returns\n",
    "        y_hat: (N, T2)\n",
    "        '''\n",
    "        decoder_inputs, y, y_seqlen, sents2 = ys\n",
    "\n",
    "        decoder_inputs = tf.ones((tf.shape(xs[0])[0], 1), tf.int32) * self.token2idx[\"<s>\"]\n",
    "        ys = (decoder_inputs, y, y_seqlen, sents2)\n",
    "\n",
    "        memory, sents1, src_masks = self.encode(xs, False)\n",
    "\n",
    "        for _ in tqdm(range(self.hp.maxlen2)):\n",
    "            logits, y_hat, y, sents2 = self.decode(ys, memory, src_masks, False)\n",
    "            if tf.reduce_sum(y_hat, 1) == self.token2idx[\"<pad>\"]: break\n",
    "\n",
    "            _decoder_inputs = tf.concat((decoder_inputs, y_hat), 1)\n",
    "            ys = (_decoder_inputs, y, y_seqlen, sents2)\n",
    "\n",
    "        # monitor a random sample\n",
    "        n = tf.random_uniform((), 0, tf.shape(y_hat)[0]-1, tf.int32)\n",
    "        sent1 = sents1[n]\n",
    "        pred = convert_idx_to_token_tensor(y_hat[n], self.idx2token)\n",
    "        sent2 = sents2[n]\n",
    "\n",
    "        tf.summary.text(\"sent1\", sent1)\n",
    "        tf.summary.text(\"pred\", pred)\n",
    "        tf.summary.text(\"sent2\", sent2)\n",
    "        summaries = tf.summary.merge_all()\n",
    "\n",
    "        return y_hat, summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = Hparams()\n",
    "parser = hparams.parser\n",
    "hp = parser.parse_args()\n",
    "# hparam define --begin\n",
    "hp.logdir='./transformer_checkpoint'\n",
    "hp.evaldir='./eval'\n",
    "hp.testdir='./test'\n",
    "hp.vocab_size=1000\n",
    "hp.batch_size=32\n",
    "hp.eval_batch_size=32\n",
    "hp.lr=0.0003\n",
    "hp.warmup_steps=2000\n",
    "hp.num_epochs=10\n",
    "hp.d_model=512\n",
    "hp.d_ff=512\n",
    "hp.num_blocks=4\n",
    "hp.num_heads=4\n",
    "hp.maxlen1=100\n",
    "hp.maxlen2=100\n",
    "hp.dropout_rate=0.3\n",
    "hp.smoothing=0.1\n",
    "# hparam define --end\n",
    "save_hparams(hp, hp.logdir)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "train_batches, num_train_batches, num_train_samples = get_batch(hp.train1, hp.train2,\n",
    "                                             hp.maxlen1, hp.maxlen2,\n",
    "                                             hp.vocab, hp.batch_size,\n",
    "                                             shuffle=True)\n",
    "eval_batches, num_eval_batches, num_eval_samples = get_batch(hp.eval1, hp.eval2,\n",
    "                                             100000, 100000,\n",
    "                                             hp.vocab, hp.batch_size,\n",
    "                                             shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = tf.data.Iterator.from_structure(train_batches.output_types, train_batches.output_shapes)\n",
    "xs, ys = iter.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_init_op = iter.make_initializer(train_batches)\n",
    "eval_init_op = iter.make_initializer(eval_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, ckpt='./transformer_checkpoints', d_ff=512, d_model=512, dropout_rate=0.3, eval1='./iwslt2016/segmented/eval.de.bpe', eval2='./iwslt2016/segmented/eval.en.bpe', eval3='./iwslt2016/prepro/eval.en', eval_batch_size=32, evaldir='./eval', f='/home/duclv/.local/share/jupyter/runtime/kernel-5beeed36-9773-48f7-ae30-3a5547a9f6ea.json', logdir='./transformer_checkpoint', lr=0.0003, maxlen1=100, maxlen2=100, num_blocks=4, num_epochs=10, num_heads=4, smoothing=0.1, test1='./iwslt2016/segmented/test.de.bpe', test2='./iwslt2016/prepro/test.en', test_batch_size=128, testdir='./test', train1='./iwslt2016/segmented/train.de.bpe', train2='./iwslt2016/segmented/train.en.bpe', vocab='./iwslt2016/segmented/bpe.vocab', vocab_size=1000, warmup_steps=2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:17<00:00,  1.98s/it]\n"
     ]
    }
   ],
   "source": [
    "print(hp)\n",
    "m = Transformer(hp)\n",
    "loss, train_op, global_step, train_summaries = m.train(xs, ys)\n",
    "y_hat, eval_summaries = m.eval(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Variables info has been saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_params:  21241347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 2966/29661 [09:49<7:34:39,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu_score_report:  BLEU = 5.96, 31.0/10.1/3.5/1.2 (BP=0.981, ration=0.981)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 5932/29661 [20:49<1:07:34,  5.85it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu_score_report:  BLEU = 8.53, 35.0/13.3/5.4/2.1 (BP=0.999, ration=0.999)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 8898/29661 [30:58<1:01:51,  5.59it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu_score_report:  BLEU = 9.82, 38.1/15.5/6.7/3.0 (BP=0.946, ration=0.947)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 11864/29661 [41:06<54:08,  5.48it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu_score_report:  BLEU = 11.13, 39.9/17.0/7.8/3.7 (BP=0.943, ration=0.945)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 14830/29661 [51:13<46:41,  5.29it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu_score_report:  BLEU = 11.75, 40.6/17.7/8.3/4.1 (BP=0.941, ration=0.943)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 17796/29661 [1:01:20<36:25,  5.43it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu_score_report:  BLEU = 12.24, 40.9/18.2/8.5/4.1 (BP=0.967, ration=0.968)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 20762/29661 [1:11:28<31:41,  4.68it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu_score_report:  BLEU = 13.00, 42.1/19.1/9.2/4.8 (BP=0.948, ration=0.949)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 23728/29661 [1:21:34<21:29,  4.60it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu_score_report:  BLEU = 13.29, 42.1/19.1/9.4/4.9 (BP=0.962, ration=0.962)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 26694/29661 [1:31:42<09:15,  5.34it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu_score_report:  BLEU = 13.74, 43.2/20.2/10.0/5.2 (BP=0.944, ration=0.946)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 29660/29661 [1:41:48<00:00,  5.05it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu_score_report:  BLEU = 13.69, 41.9/19.4/9.5/4.9 (BP=0.983, ration=0.983)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29661/29661 [1:42:33<00:00,  4.82it/s]\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver(max_to_keep=hp.num_epochs)\n",
    "with tf.Session() as sess:\n",
    "    ckpt = tf.train.latest_checkpoint(hp.logdir)\n",
    "    if ckpt is None:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        save_variable_specs(os.path.join(hp.logdir, \"specs\"))\n",
    "    else:\n",
    "        saver.restore(sess, ckpt)\n",
    "\n",
    "    summary_writer = tf.summary.FileWriter(hp.logdir, sess.graph)\n",
    "\n",
    "    sess.run(train_init_op)\n",
    "    total_steps = hp.num_epochs * num_train_batches\n",
    "    _gs = sess.run(global_step)\n",
    "    for i in tqdm(range(_gs, total_steps+1)):\n",
    "        _, _gs, _summary = sess.run([train_op, global_step, train_summaries])\n",
    "        epoch = math.ceil(_gs / num_train_batches)\n",
    "        summary_writer.add_summary(_summary, _gs)\n",
    "\n",
    "        if _gs and _gs % num_train_batches == 0:\n",
    "            _loss = sess.run(loss) # train loss\n",
    "\n",
    "            _, _eval_summaries = sess.run([eval_init_op, eval_summaries])\n",
    "            summary_writer.add_summary(_eval_summaries, _gs)\n",
    "\n",
    "            hypotheses = get_hypotheses(num_eval_batches, num_eval_samples, sess, y_hat, m.idx2token)\n",
    "\n",
    "            model_output = \"iwslt2016_E%02dL%.2f\" % (epoch, _loss)\n",
    "            if not os.path.exists(hp.evaldir): os.makedirs(hp.evaldir)\n",
    "            translation = os.path.join(hp.evaldir, model_output)\n",
    "            with open(translation, 'w') as fout:\n",
    "                fout.write(\"\\n\".join(hypotheses))\n",
    "\n",
    "            calc_bleu(hp.eval3, translation)\n",
    "\n",
    "            ckpt_name = os.path.join(hp.logdir, model_output)\n",
    "            saver.save(sess, ckpt_name, global_step=_gs)\n",
    "\n",
    "            sess.run(train_init_op)\n",
    "    summary_writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.ckpt = './transformer_checkpoint'\n",
    "load_hparams(hp, hp.ckpt)\n",
    "\n",
    "test_batches, num_test_batches, num_test_samples  = get_batch(hp.test1, hp.test1,\n",
    "                                              100000, 100000,\n",
    "                                              hp.vocab, hp.test_batch_size,\n",
    "                                              shuffle=False)\n",
    "iter = tf.data.Iterator.from_structure(test_batches.output_types, test_batches.output_shapes)\n",
    "xs, ys = iter.get_next()\n",
    "\n",
    "test_init_op = iter.make_initializer(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:52<00:00,  1.13s/it]\n"
     ]
    }
   ],
   "source": [
    "y_hat, _ = m.eval(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./transformer_checkpoint/iwslt2016_E10L2.49-59320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./transformer_checkpoint/iwslt2016_E10L2.49-59320\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[128,138,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node encoder_2/embedding_lookup (defined at <ipython-input-12-5ce68a37eb0f>:31)  = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@decoder_200/embedding_lookup\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](shared_weight_matrix/concat, IteratorGetNext_1/_883, encoder_2/embedding_lookup/axis)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node decoder_137/num_blocks_1/positionwise_feedforward/dense_1/Tensordot/Shape/_8337}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_43973...rdot/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'encoder_2/embedding_lookup', defined at:\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-34-df2911cee8c7>\", line 1, in <module>\n    y_hat, _ = m.eval(xs, ys)\n  File \"<ipython-input-12-5ce68a37eb0f>\", line 153, in eval\n    memory, sents1, src_masks = self.encode(xs, False)\n  File \"<ipython-input-12-5ce68a37eb0f>\", line 31, in encode\n    enc = tf.nn.embedding_lookup(self.embeddings, x) # (N, T1, d_model)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 313, in embedding_lookup\n    transform_fn=None)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 133, in _embedding_lookup_and_transform\n    result = _clip(array_ops.gather(params[0], ids, name=name),\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2675, in gather\n    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3332, in gather_v2\n    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[128,138,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node encoder_2/embedding_lookup (defined at <ipython-input-12-5ce68a37eb0f>:31)  = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@decoder_200/embedding_lookup\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](shared_weight_matrix/concat, IteratorGetNext_1/_883, encoder_2/embedding_lookup/axis)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node decoder_137/num_blocks_1/positionwise_feedforward/dense_1/Tensordot/Shape/_8337}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_43973...rdot/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[128,138,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node encoder_2/embedding_lookup}} = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@decoder_200/embedding_lookup\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](shared_weight_matrix/concat, IteratorGetNext_1/_883, encoder_2/embedding_lookup/axis)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node decoder_137/num_blocks_1/positionwise_feedforward/dense_1/Tensordot/Shape/_8337}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_43973...rdot/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-1b5043597e89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_init_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mhypotheses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hypotheses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_test_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_test_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx2token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/homework/courses/class_Deep_Learning/Assignment3/transformer_utils.py\u001b[0m in \u001b[0;36mget_hypotheses\u001b[0;34m(num_batches, num_samples, sess, tensor, dict)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0mhypotheses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0mhypotheses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0mhypotheses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypotheses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[128,138,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node encoder_2/embedding_lookup (defined at <ipython-input-12-5ce68a37eb0f>:31)  = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@decoder_200/embedding_lookup\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](shared_weight_matrix/concat, IteratorGetNext_1/_883, encoder_2/embedding_lookup/axis)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node decoder_137/num_blocks_1/positionwise_feedforward/dense_1/Tensordot/Shape/_8337}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_43973...rdot/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'encoder_2/embedding_lookup', defined at:\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-34-df2911cee8c7>\", line 1, in <module>\n    y_hat, _ = m.eval(xs, ys)\n  File \"<ipython-input-12-5ce68a37eb0f>\", line 153, in eval\n    memory, sents1, src_masks = self.encode(xs, False)\n  File \"<ipython-input-12-5ce68a37eb0f>\", line 31, in encode\n    enc = tf.nn.embedding_lookup(self.embeddings, x) # (N, T1, d_model)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 313, in embedding_lookup\n    transform_fn=None)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 133, in _embedding_lookup_and_transform\n    result = _clip(array_ops.gather(params[0], ids, name=name),\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2675, in gather\n    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3332, in gather_v2\n    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[128,138,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node encoder_2/embedding_lookup (defined at <ipython-input-12-5ce68a37eb0f>:31)  = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@decoder_200/embedding_lookup\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](shared_weight_matrix/concat, IteratorGetNext_1/_883, encoder_2/embedding_lookup/axis)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node decoder_137/num_blocks_1/positionwise_feedforward/dense_1/Tensordot/Shape/_8337}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_43973...rdot/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "with tf.Session() as sess:\n",
    "    ckpt_ = tf.train.latest_checkpoint(hp.ckpt)\n",
    "    ckpt = hp.ckpt if ckpt_ is None else ckpt_ # None: ckpt is a file. otherwise dir.\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    saver.restore(sess, ckpt)\n",
    "\n",
    "    sess.run(test_init_op)\n",
    "\n",
    "    hypotheses = get_hypotheses(num_test_batches, num_test_samples, sess, y_hat, m.idx2token)\n",
    "\n",
    "    model_output = ckpt.split(\"/\")[-1]\n",
    "    if not os.path.exists(hp.testdir): os.makedirs(hp.testdir)\n",
    "    translation = os.path.join(hp.testdir, model_output)\n",
    "    with open(translation, 'w') as fout:\n",
    "        fout.write(\"\\n\".join(hypotheses))\n",
    "\n",
    "    calc_bleu(hp.test2, translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep-learning-19] *",
   "language": "python",
   "name": "conda-env-deep-learning-19-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
