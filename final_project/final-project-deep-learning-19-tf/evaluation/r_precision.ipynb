{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M2177.003100 Deep Learning <br> Final Proejct: Text to Image Synthesis (Tensorflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In order to unify a scoring tool (fairness), we decided to use one evaluation code. The evaluation code for pytorch and tensorflow users is the same. **\n",
    "\n",
    "### Submitting your work:\n",
    "<font color=red>**DO NOT clear the R-precision score **</font> so that TAs can grade the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import sys, os\n",
    "sys.path.append('..')\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "from miscc.config import cfg, cfg_from_file\n",
    "\n",
    "cfg_from_file('../cfg/eval_birds.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    \"\"\"\n",
    "    Returns cosine similarity between v1 and v2\n",
    "    \"\"\"\n",
    "    cost = tf.reduce_sum(tf.multiply(v1, v2), 1) / (tf.sqrt(tf.reduce_sum(tf.multiply(v1, v1), 1)) * tf.sqrt(tf.reduce_sum(tf.multiply(v2, v2), 1)))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_precision.npz\n",
      "(916, 32, 128)\n",
      "(916, 32, 128)\n",
      "(916, 9, 32, 128)\n"
     ]
    }
   ],
   "source": [
    "path = cfg.R_PRECISION_FILE\n",
    "print(path)\n",
    "\n",
    "'''\n",
    "Size of input features\n",
    "true_cnn_features = [cfg.NUM_BATCH_FOR_TEST, cfg.TRAIN.BATCH_SIZE, cfg.TEXT.EMBEDDING_DIM]\n",
    "true_rnn_features = [cfg.NUM_BATCH_FOR_TEST, cfg.TRAIN.BATCH_SIZE, cfg.TEXT.EMBEDDING_DIM]\n",
    "wrong_rnn_features = [cfg.NUM_BATCH_FOR_TEST, cfg.WRONG_CAPTION, cfg.TRAIN.BATCH_SIZE, cfg.TEXT.EMBEDDING_DIM]\n",
    "'''\n",
    "\n",
    "if path.endswith('.npz'):\n",
    "    f = np.load(path)\n",
    "    true_cnn_features, true_rnn_features, wrong_rnn_features = f['true_cnn'], f['true_rnn'], f['wrong_rnn']\n",
    "    f.close()\n",
    "\n",
    "print(true_cnn_features.shape)\n",
    "print(true_rnn_features.shape)\n",
    "print(wrong_rnn_features.shape)\n",
    "\n",
    "cfg.NUM_BATCH_FOR_TEST = true_cnn_features.shape[0]\n",
    "cfg.BATCH_SIZE = true_cnn_features.shape[1]\n",
    "cfg.TEXT.EMBEDDING_DIM = true_cnn_features.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_real_image = tf.placeholder('float32', [cfg.NUM_BATCH_FOR_TEST * cfg.BATCH_SIZE, cfg.TEXT.EMBEDDING_DIM], name='real_image')\n",
    "t_real_cap = tf.placeholder('float32', [cfg.NUM_BATCH_FOR_TEST * cfg.BATCH_SIZE, cfg.TEXT.EMBEDDING_DIM], name='real_caption')\n",
    "t_wrong_cap = tf.placeholder('float32', [cfg.NUM_BATCH_FOR_TEST * cfg.BATCH_SIZE, cfg.TEXT.EMBEDDING_DIM], name='wrong_caption')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-precision: 0.42218205\n"
     ]
    }
   ],
   "source": [
    "true_cnn_features = np.reshape(true_cnn_features, (-1, cfg.TEXT.EMBEDDING_DIM))\n",
    "true_rnn_features = np.reshape(true_rnn_features, (-1, cfg.TEXT.EMBEDDING_DIM))\n",
    "\n",
    "true_cnn_true_rnn = cosine_similarity(t_real_image, t_real_cap)\n",
    "true_cnn_wrong_rnn = cosine_similarity(t_real_image, t_wrong_cap)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    cs_b_real_real = sess.run(true_cnn_true_rnn, feed_dict={t_real_image:true_cnn_features, t_real_cap:true_rnn_features})\n",
    "    cs_b_real_wrong = []\n",
    "    for i in range(cfg.WRONG_CAPTION):\n",
    "        cs_b_real_wrong.append(sess.run(true_cnn_wrong_rnn, feed_dict={t_real_image: true_cnn_features,\n",
    "                                                                  t_wrong_cap: np.reshape(wrong_rnn_features[:, i, :, :], (-1, cfg.TEXT.EMBEDDING_DIM))}))\n",
    "\n",
    "    cs_b_real_wrong = np.asarray(cs_b_real_wrong)\n",
    "\n",
    "    total_cs = tf.concat((np.expand_dims(cs_b_real_real, 0), cs_b_real_wrong), axis=0)\n",
    "\n",
    "    ranked = tf.argmax(total_cs, 0)\n",
    "    correct_ranking = tf.equal(ranked, 0)\n",
    "\n",
    "    r_precision = tf.reduce_mean(tf.cast(correct_ranking, tf.float32))\n",
    "\n",
    "    print('R-precision: ' + str(sess.run(r_precision)))\n",
    "    # R-precision: 0.43538597 - Batchsize = 16, 50 epoch\n",
    "    # R-precision: 0.47864357 - 190 epoch, 32 batchsize\n",
    "    # R-precision: 0.41112855 - 300 epoch => checked\n",
    "    # R-precision: 0.33859852 - 350 epoch => checked\n",
    "    # R-precision: 0.32672626 - 360 epoch\n",
    "    # R-precision: 0.48556906 - 370 epoch\n",
    "    # R-precision: 0.42218205 - 380 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep-learning-19] *",
   "language": "python",
   "name": "conda-env-deep-learning-19-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
