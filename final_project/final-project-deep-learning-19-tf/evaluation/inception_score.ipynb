{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M2177.003100 Deep Learning <br> Final Proejct: Text to Image Synthesis (Tensorflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In order to unify a scoring tool (fairness), we decided to use one evaluation code. The evaluation code for pytorch and tensorflow users is the same. **\n",
    "\n",
    "### Submitting your work:\n",
    "<font color=red>**DO NOT clear the Inception score (mean and std) **</font> so that TAs can grade the results.\n",
    "The synthesized images should be size 256. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inception.slim import slim\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import math\n",
    "import os.path\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "import scipy.misc\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from miscc.config import cfg, cfg_from_file\n",
    "\n",
    "cfg_from_file('../cfg/eval_birds.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_images\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dir ='./inception_finetuned_models/birds_valid299/model.ckpt' # dont change it\n",
    "\n",
    "image_folder = cfg.TEST.GENERATED_TEST_IMAGES.split('/')[2]\n",
    "\n",
    "num_classes = 50\n",
    "splits = 10\n",
    "batch_size = 32\n",
    "\n",
    "# Batch normalization. Constant governing the exponential moving average of\n",
    "# the 'global' mean and variance for all activations.\n",
    "BATCHNORM_MOVING_AVERAGE_DECAY = 0.9997\n",
    "\n",
    "# The decay to use for the moving average.\n",
    "MOVING_AVERAGE_DECAY = 0.9999\n",
    "\n",
    "print(image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    # print('img', img.shape, img.max(), img.min())\n",
    "    # img = Image.fromarray(img, 'RGB')\n",
    "    if len(img.shape) == 2:\n",
    "        img = np.resize(img, (img.shape[0], img.shape[1], 3))\n",
    "    img = scipy.misc.imresize(img, (299, 299, 3),\n",
    "                              interp='bilinear')\n",
    "    img = img.astype(np.float32)\n",
    "    # [0, 255] --> [0, 1] --> [-1, 1]\n",
    "    img = img / 127.5 - 1.\n",
    "    # print('img', img.shape, img.max(), img.min())\n",
    "    return np.expand_dims(img, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inception_score(sess, images, pred_op, splits, batch_size):\n",
    "    #splits = splits\n",
    "    # assert(type(images) == list)\n",
    "    assert(type(images[0]) == np.ndarray)\n",
    "    assert(len(images[0].shape) == 3)\n",
    "    assert(np.max(images[0]) > 10)\n",
    "    assert(np.min(images[0]) >= 0.0)\n",
    "    bs = batch_size\n",
    "    preds = []\n",
    "    num_examples = len(images)\n",
    "    n_batches = int(math.floor(float(num_examples) / float(bs)))\n",
    "    indices = list(np.arange(num_examples))\n",
    "    np.random.shuffle(indices)\n",
    "    for i in range(n_batches):\n",
    "        inp = []\n",
    "        # print('i*bs', i*bs)\n",
    "        for j in range(bs):\n",
    "            if (i*bs + j) == num_examples:\n",
    "                break\n",
    "            img = images[indices[i*bs + j]]\n",
    "            # print('*****', img.shape)\n",
    "            img = preprocess(img)\n",
    "            inp.append(img)\n",
    "        # print(\"%d of %d batches\" % (i, n_batches))\n",
    "        # inp = inps[(i * bs):min((i + 1) * bs, len(inps))]\n",
    "        inp = np.concatenate(inp, 0)\n",
    "        #  print('inp', inp.shape)\n",
    "        pred = sess.run(pred_op, {'inputs:0': inp})\n",
    "        preds.append(pred)\n",
    "        # if i % 100 == 0:\n",
    "        #     print('Batch ', i)\n",
    "        #     print('inp', inp.shape, inp.max(), inp.min())\n",
    "    preds = np.concatenate(preds, 0)\n",
    "    scores = []\n",
    "    for i in range(splits):\n",
    "        istart = i * preds.shape[0] // splits\n",
    "        iend = (i + 1) * preds.shape[0] // splits\n",
    "        part = preds[istart:iend, :]\n",
    "        kl = (part * (np.log(part) -\n",
    "              np.log(np.expand_dims(np.mean(part, 0), 0))))\n",
    "        kl = np.mean(np.sum(kl, 1))\n",
    "        scores.append(np.exp(kl))\n",
    "    print('mean:', \"%.2f\" % np.mean(scores), 'std:', \"%.2f\" % np.std(scores))\n",
    "    return np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fullpath):\n",
    "    print(fullpath)\n",
    "    images = []\n",
    "    for path, subdirs, files in os.walk(fullpath):\n",
    "        for name in files:\n",
    "            if name.rfind('jpg') != -1 or name.rfind('png') != -1:\n",
    "                filename = os.path.join(path, name)\n",
    "                #print('filename', filename)\n",
    "                #print('path', path, '\\nname', name)\n",
    "                #print('filename', filename)\n",
    "                if os.path.isfile(filename):\n",
    "                    img = scipy.misc.imread(filename)\n",
    "                    images.append(img)\n",
    "    print('images', len(images), images[0].shape)\n",
    "    return images, (images[0].shape[0] == 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(images, num_classes, for_training=False, restore_logits=True,\n",
    "              scope=None):\n",
    "    \"\"\"Build Inception v3 model architecture.\n",
    "\n",
    "    See here for reference: http://arxiv.org/abs/1512.00567\n",
    "\n",
    "    Args:\n",
    "    images: Images returned from inputs() or distorted_inputs().\n",
    "    num_classes: number of classes\n",
    "    for_training: If set to `True`, build the inference model for training.\n",
    "      Kernels that operate differently for inference during training\n",
    "      e.g. dropout, are appropriately configured.\n",
    "    restore_logits: whether or not the logits layers should be restored.\n",
    "      Useful for fine-tuning a model with different num_classes.\n",
    "    scope: optional prefix string identifying the ImageNet tower.\n",
    "\n",
    "    Returns:\n",
    "    Logits. 2-D float Tensor.\n",
    "    Auxiliary Logits. 2-D float Tensor of side-head. Used for training only.\n",
    "    \"\"\"\n",
    "    # Parameters for BatchNorm.\n",
    "    batch_norm_params = {\n",
    "      # Decay for the moving averages.\n",
    "      'decay': BATCHNORM_MOVING_AVERAGE_DECAY,\n",
    "      # epsilon to prevent 0s in variance.\n",
    "      'epsilon': 0.001,\n",
    "    }\n",
    "    # Set weight_decay for weights in Conv and FC layers.\n",
    "    with slim.arg_scope([slim.ops.conv2d, slim.ops.fc], weight_decay=0.00004):\n",
    "        with slim.arg_scope([slim.ops.conv2d],\n",
    "                            stddev=0.1,\n",
    "                            activation=tf.nn.relu,\n",
    "                            batch_norm_params=batch_norm_params):\n",
    "            logits, endpoints = slim.inception.inception_v3(\n",
    "              images,\n",
    "              dropout_keep_prob=0.8,\n",
    "              num_classes=num_classes,\n",
    "              is_training=for_training,\n",
    "              restore_logits=restore_logits,\n",
    "              scope=scope)\n",
    "\n",
    "    # Grab the logits associated with the side head. Employed during training.\n",
    "    auxiliary_logits = endpoints['aux_logits']\n",
    "\n",
    "    return logits, auxiliary_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./inception_finetuned_models/birds_valid299/model.ckpt\n",
      "Restore the model from ./inception_finetuned_models/birds_valid299/model.ckpt).\n",
      "generated_images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/ipykernel_launcher.py:12: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images 29280 (256, 256, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duclv/anaconda3/envs/deep-learning-19/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 2.52 std: 0.02\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=config) as sess:\n",
    "        # Number of classes in the Dataset label set plus 1.\n",
    "        # Label 0 is reserved for an (unused) background class.\n",
    "        num_classes = num_classes + 1\n",
    "\n",
    "        # Build a Graph that computes the logits predictions from the\n",
    "        # inference model.\n",
    "        inputs = tf.placeholder(\n",
    "            tf.float32, [batch_size, 299, 299, 3],\n",
    "            name='inputs')\n",
    "        # print(inputs)\n",
    "\n",
    "        logits, _ = inference(inputs, num_classes)\n",
    "        # calculate softmax after remove 0 which reserve for BG\n",
    "        known_logits = \\\n",
    "            tf.slice(logits, [0, 1],\n",
    "                     [batch_size, num_classes - 1])\n",
    "        pred_op = tf.nn.softmax(known_logits)\n",
    "\n",
    "        # Restore the moving average version of the\n",
    "        # learned variables for eval.\n",
    "        variable_averages = \\\n",
    "            tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY)\n",
    "        variables_to_restore = variable_averages.variables_to_restore()\n",
    "        saver = tf.train.Saver(variables_to_restore)\n",
    "        saver.restore(sess, checkpoint_dir)\n",
    "        print('Restore the model from %s).' % checkpoint_dir)\n",
    "        images, size_match = load_data(image_folder)\n",
    "        if not size_match:\n",
    "            print('Error: the generated images should be size 256')\n",
    "            exit()\n",
    "        get_inception_score(sess, images, pred_op, splits, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep-learning-19] *",
   "language": "python",
   "name": "conda-env-deep-learning-19-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
