{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M2177.003100 Deep Learning <br> Assignment #4 Implementing Conditional Generative Adversarial Nets - part3 Labeld Face Data\n",
    "\n",
    "Copyright (C) Data Science Laboratory, Seoul National University. This material is for educational uses only. Some contents are based on the material provided by other paper/book authors and may be copyrighted by them. Written by Jaeyoon Yoo, November 2017\n",
    "\n",
    "In this notebook, you will learn how to implement conditional Genverative Adversarial Nets (cGANs) <br>\n",
    "The goal here is to build GANs that draw a face given its label. You can draw a black male/black female/white male/white female as you gives an input at the end of training. <br> \n",
    "\n",
    "**Note**: certain details are missing or ambiguous on purpose, in order to test your knowledge on the related materials. However, if you really feel that something essential is missing and cannot proceed to the next step, then contact the teaching staff with clear description of your problem.\n",
    "\n",
    "### Submitting your work:\n",
    "<font color=red>**DO NOT clear the final outputs**</font> so that TAs can grade both your code and results.  \n",
    "Once you have done **all parts**, run the *CollectSubmission.sh* script with your **Team number** as input argument. <br>\n",
    "This will produce a zipped file called *[Your team number].zip*. Please submit this file on ETL. &nbsp;&nbsp; (Usage: ./*CollectSubmission.sh* &nbsp; Team_#)\n",
    "\n",
    "### Some helpful tutorials and references for assignment #3:\n",
    "- [1] TensorFlow official tutorials. [[link]](https://www.tensorflow.org/get_started/get_started)\n",
    "- [2] Stanford CS231n lectures. [[link]](http://cs231n.stanford.edu/)\n",
    "- [3] Goodfellow, Ian, et al. \"Generative adversarial nets.\" Advances in neural information processing systems. 2014.\n",
    "- [4] Mirza, Mehdi, and Simon Osindero. \"Conditional generative adversarial nets.\" arXiv preprint arXiv:1411.1784 (2014).\n",
    "- [5] Radford, Alec, Luke Metz, and Soumith Chintala. \"Unsupervised representation learning with deep convolutional generative adversarial networks.\" arXiv preprint arXiv:1511.06434 (2015)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Download and load Face datasets\n",
    "Unzip the face_dataset.tar.gz in data directory as follows.<br>\n",
    "**cd ./data**<br>\n",
    "**tar -xf face_dataset.tar.gz**<br>\n",
    "\n",
    "Following is how to load the data. Modify  *data_dir* to be the directory the data is in. Or you will get an error.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_face\n",
    "data_dir = './data/face_dataset'\n",
    "im, label = load_face(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 13143 images and corresponding lables. Labels have three values. Following is the detail:\n",
    "\n",
    "Label1 - Male/Female : positive value means male<br>\n",
    "Label2 - White/Not white : positive value means White<br>\n",
    "Lable3 - Black/Not black : positive value menas black<br>\n",
    "The large value represents the more property it has.\n",
    "\n",
    "Note that the labels are not normalized and check the data by runing and modifying following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "for i in range(5):\n",
    "    plt.imshow(im[i])\n",
    "    plt.show()\n",
    "    print(label[i])\n",
    "    print(im[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"1\"></a> 1. Build a network\n",
    "\n",
    "In this section, you will implement neural networks for (1) generative model (2) discriminative model. You can reuse your code in part1 and improve it. Just write the code in whatever way you find most clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_face\n",
    "from utils import getNext_batch\n",
    "from utils import save_images\n",
    "from utils import vis_square\n",
    "from utils import sample_label\n",
    "from utils import sample_label_face\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import cv2\n",
    "\n",
    "from ops import conv2d\n",
    "from ops import lrelu\n",
    "from ops import de_conv\n",
    "from ops import fully_connect\n",
    "from ops import conv_cond_concat\n",
    "from ops import batch_normal\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "learning_rate = 0.0002\n",
    "batch_size = 128\n",
    "EPOCH = 100\n",
    "loss_step    = 50\n",
    "display_step = 50\n",
    "sample_size = 100\n",
    "y_dim = 3\n",
    "channel = 3\n",
    "output_size = 64\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time for a generative model. You can change anything including the argument If you need. Feel free to change it and improve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gern_net(batch_size, z , y ,sample_size, y_dim, output_size):\n",
    "    #### TODO ####\n",
    "    with tf.variable_scope('gen'):\n",
    "        w_init = tf.truncated_normal_initializer(mean=0.0, stddev=0.02)\n",
    "        b_init = tf.constant_initializer(0.0)\n",
    "\n",
    "        # concat layer\n",
    "        z_input = tf.reshape(z, [-1, 1, 1, sample_size])\n",
    "        y_label = tf.reshape(y, [-1, 1, 1, y_dim])\n",
    "        inputs = tf.concat([z, y], 1)\n",
    "        \n",
    "        # project layer\n",
    "        proj_size = 4*4*1024\n",
    "        W = tf.get_variable(\"W0\", [sample_size + y_dim, proj_size], initializer=w_init)\n",
    "        b = tf.get_variable(\"b0\", [proj_size], initializer=b_init)\n",
    "        projected = lrelu(batch_normal(fully_connect(inputs, W, b), scope='bn0'))\n",
    "        reshape = tf.reshape(projected, [batch_size, 4, 4, 1024])\n",
    "\n",
    "        # 1st hidden layer\n",
    "        W = tf.get_variable(\"W1\", [5, 5, 512, 1024], initializer=w_init)\n",
    "        b = tf.get_variable(\"b1\", [512], initializer=b_init)\n",
    "        deconv1 = lrelu(batch_normal(de_conv(reshape, W, b, [batch_size, 8, 8, 512]), scope='bn1'))\n",
    "\n",
    "        # 2nd hidden layer\n",
    "        W = tf.get_variable(\"W2\", [5, 5, 256, 512], initializer=w_init)\n",
    "        b = tf.get_variable(\"b2\", [256], initializer=b_init)\n",
    "        deconv2 = lrelu(batch_normal(de_conv(deconv1, W, b, [batch_size, 16, 16, 256]), scope='bn2'))\n",
    "        \n",
    "        # 3nd hidden layer\n",
    "        W = tf.get_variable(\"W3\", [5, 5, 128, 256], initializer=w_init)\n",
    "        b = tf.get_variable(\"b3\", [128], initializer=b_init)\n",
    "        deconv3 = lrelu(batch_normal(de_conv(deconv2, W, b, [batch_size, 32, 32, 128]), scope='bn3'))\n",
    "\n",
    "        # output layer\n",
    "        W = tf.get_variable(\"W4\", [5, 5, 3, 128], initializer=w_init)\n",
    "        b = tf.get_variable(\"b4\", [3], initializer=b_init)\n",
    "        deconv3 = de_conv(deconv3, W, b, [batch_size, 64, 64, 3])\n",
    "        o = tf.nn.tanh(deconv3)\n",
    "\n",
    "        return o\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it's time for a discriminative model. Again, you can change anything if you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis_net(data_array , y, batch_size, y_dim, reuse=False):\n",
    "    #### TODO ####\n",
    "    with tf.variable_scope('dis', reuse=reuse):\n",
    "        w_init = tf.truncated_normal_initializer(mean=0.0, stddev=0.02)\n",
    "        b_init = tf.constant_initializer(0.0)\n",
    "\n",
    "        yb = tf.reshape(y, [batch_size, 1, 1, y_dim])\n",
    "        x = conv_cond_concat(data_array, yb)\n",
    "\n",
    "        # 1st hidden layer\n",
    "        W = tf.get_variable(\"W1\", [5, 5, x.get_shape()[-1], channel+y_dim], initializer=w_init)\n",
    "        b = tf.get_variable(\"b1\", [channel+y_dim], initializer=b_init)\n",
    "        conv1 = lrelu(conv2d(x, W, b))\n",
    "        \n",
    "        # 2nd hidden layer\n",
    "        W = tf.get_variable(\"W2\", [5, 5, conv1.get_shape()[-1], 64], initializer=w_init)\n",
    "        b = tf.get_variable(\"b2\", [64], initializer=b_init)\n",
    "        conv2 = lrelu(batch_normal(conv2d(conv1, W, b), scope='bn2'))\n",
    "        conv2_flatten = tf.reshape(conv2, [batch_size, -1])\n",
    "        \n",
    "        # 3rd hidden layer\n",
    "        W = tf.get_variable(\"W3\", [conv2_flatten.get_shape()[-1], 1024], initializer=w_init)\n",
    "        b = tf.get_variable(\"b3\", [1024], initializer=b_init)\n",
    "        out3 = lrelu(batch_normal(fully_connect(conv2_flatten, W, b), scope='bn3'))\n",
    "\n",
    "        # output layer\n",
    "        W = tf.get_variable(\"W4\", [1024, 1], initializer=w_init)\n",
    "        b = tf.get_variable(\"b4\", [1], initializer=b_init)\n",
    "        logits = fully_connect(out3, W, b)\n",
    "        o = tf.nn.sigmoid(logits)\n",
    "\n",
    "        return o, logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"2\"></a> 2. Build a main part and train it\n",
    "\n",
    "In this section, you will implement the main part. Then run the code and check the model draws the face properly.\n",
    "\n",
    "When you are done, run the following to check your implementations.\n",
    "\n",
    "Following code will make 'samples_for_test' directory that resulting image will be saved in. You can change the directory as you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_mnist\n",
    "from utils import save_images\n",
    "from utils import vis_square\n",
    "from utils import sample_label\n",
    "from utils import getNext_batch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "sample_dir = 'samples_for_test_faces'\n",
    "\n",
    "if os.path.exists(sample_dir) == False:\n",
    "    os.makedirs(sample_dir)\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to fill in the main part. You can copy the part1 code or write your own code.\n",
    "\n",
    "Your goal is to **generate 4 row and 8 column images(32 total)**.\n",
    "\n",
    "**Each row should correspond to each label**.\n",
    "\n",
    "First row : black male<br>\n",
    "Second row: black female<br>\n",
    "Third row : white male<br>\n",
    "Fourth row: white female<br>\n",
    "\n",
    "You can use \"save_images\" method in *utils.py* to align generated image by 4*8. See part1 code to get how to use it.\n",
    "\n",
    "You must show **at least three generated images**. (At the beginning of ,in the midway of, at the end of training.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 step 50: D: loss = 1.3996160 G: loss=0.6708941 \n"
     ]
    }
   ],
   "source": [
    "#### TODO ####\n",
    "def new_sample_label_face(num):\n",
    "    label_vector = np.zeros((num,3))\n",
    "    for i in range(32):\n",
    "        if i < 8:\n",
    "            label_vector[i,0]=2  # male\n",
    "            label_vector[i,1]=-2 # not white\n",
    "            label_vector[i,2]=2  # black\n",
    "        elif i < 16:\n",
    "            label_vector[i,0]=-2 # female\n",
    "            label_vector[i,1]=-2 # not white\n",
    "            label_vector[i,2]=2  # black\n",
    "        elif i < 24:\n",
    "            label_vector[i,0]=2  # male\n",
    "            label_vector[i,1]=2  # white\n",
    "            label_vector[i,2]=-2  # not black\n",
    "        else:\n",
    "            label_vector[i,0]=-2  # female\n",
    "            label_vector[i,1]=2 # white\n",
    "            label_vector[i,2]=-2  # not black\n",
    "    return label_vector\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "sample_z = np.random.uniform(-1 , 1 , size = [batch_size , sample_size])\n",
    "\n",
    "y = tf.placeholder(tf.float32, [None , y_dim])\n",
    "\n",
    "images = tf.placeholder(tf.float32, [batch_size, output_size, output_size, channel])\n",
    "\n",
    "z = tf.placeholder(tf.float32, [None , sample_size])\n",
    "\n",
    "fake_images = gern_net(batch_size, z , y ,sample_size, y_dim,output_size)\n",
    "\n",
    "##the loss of gerenate network\n",
    "D_pro , D_logits = dis_net(images, y , batch_size, y_dim,  False)\n",
    "\n",
    "G_pro, G_logits = dis_net(fake_images , y , batch_size, y_dim, True)\n",
    "\n",
    "# DEFINE LOSS FUNCTION #\n",
    "\n",
    "D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logits, labels=tf.ones_like(D_logits)))\n",
    "D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=G_logits, labels=tf.zeros_like(G_logits)))\n",
    "D_loss = D_loss_real + D_loss_fake\n",
    "G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=G_logits, labels=tf.ones_like(G_logits)))\n",
    "\n",
    "#############\n",
    "\n",
    "t_vars = tf.trainable_variables()\n",
    "\n",
    "d_var = [var for var in t_vars if 'dis' in var.name]\n",
    "g_var = [var for var in t_vars if 'gen' in var.name]\n",
    "\n",
    "opti_D = tf.train.AdamOptimizer(learning_rate=learning_rate , beta1=0.5).minimize(D_loss , var_list=d_var)\n",
    "opti_G = tf.train.AdamOptimizer(learning_rate=learning_rate , beta1=0.5).minimize(G_loss , var_list=g_var)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "\n",
    "    sess.run(init)\n",
    "    e = 0\n",
    "    step = 0\n",
    "\n",
    "    while e <= EPOCH:\n",
    "        batch_num = 0\n",
    "        while batch_num < len(im) / batch_size - 1:\n",
    "\n",
    "            step = step + 1\n",
    "\n",
    "            realbatch_array , real_labels = getNext_batch(im , label , batch_num, batch_size)\n",
    "            \n",
    "            #Get the z\n",
    "            batch_z = np.random.uniform(-1 , 1 , size=[batch_size , sample_size])\n",
    "\n",
    "            _ = sess.run(opti_D, feed_dict={images:realbatch_array, z:batch_z , y:real_labels})\n",
    "            _ = sess.run(opti_G, feed_dict={z: batch_z , y:real_labels})\n",
    "\n",
    "            batch_num += 1\n",
    "\n",
    "            if step % loss_step == 0:\n",
    "\n",
    "                d_get_loss = sess.run(D_loss , feed_dict = {images:realbatch_array , z:batch_z , y:real_labels})\n",
    "                g_get_loss = sess.run(G_loss , feed_dict = {z: batch_z , y:real_labels})\n",
    "                print(\"EPOCH %d step %d: D: loss = %.7f G: loss=%.7f \" % (e , step , d_get_loss , g_get_loss))\n",
    "\n",
    "            #if np.mod(step , display_step) == 1:\n",
    "        if np.mod(e , 10) == 0:\n",
    "\n",
    "            sample_images = sess.run(fake_images , feed_dict={z:sample_z , y:new_sample_label_face(batch_size)})\n",
    "            sample_images = sample_images[:32,:,:,:]\n",
    "            image_name = './{}/train_{:02d}_{:04d}.png'.format(sample_dir , e , step)\n",
    "            save_images(sample_images , [4,8] , image_name)\n",
    "        \n",
    "            img = mpimg.imread(image_name)\n",
    "            imgplot = plt.imshow(img)\n",
    "            plt.show()\n",
    "\n",
    "        e = e + 1\n",
    "        batch_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
